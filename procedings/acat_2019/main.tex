% !TeX program = lualatex
% !BIB program = bibtex
% !TeX encoding = utf8

\documentclass[a4paper]{jpconf}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{markdown}
\usetikzlibrary{decorations.pathreplacing}

\bibliographystyle{iopart-num}

\begin{document}
\title{A hybrid deep learning approach to vertexing}

\author{
   Rui Fang\textsuperscript{1},
   Henry F Schreiner\textsuperscript{1,2},
   Mike D Sokoloff\textsuperscript{1},
   Constantin Weisser\textsuperscript{3} and
   Mike Williams\textsuperscript{3}
}

\address{
    \textsuperscript{1} University of Cincinnati, Cincinnati, OH, United States
}
\address{
    \textsuperscript{2} Princeton University, Princeton, NJ, United States
}
\address{
    \textsuperscript{3} Massachusetts Institute of Technology, Cambridge, MA, United States
}

\ead{hschrein@cern.ch, others}

\begin{abstract}
In the transition to Run 3 in 2021, LHCb will undergo a major luminosity upgrade, going from 1.1 to 5.6 expected visible Primary Vertices (PVs) per event, and will adopt a purely software trigger. This has fueled increased interest in alternative highly-parallel and GPU friendly algorithms for tracking and reconstruction. We will present a novel prototype algorithm for vertexing in the LHCb upgrade conditions.
We use a custom kernel to transform the sparse 3D space of hits and tracks into a dense 1D dataset, and then apply Deep Learning techniques to find PV locations. By training networks on our kernels using several Convolutional Neural Network layers, we have achieved better than 90\% efficiency with no more than 0.2 False Positives (FPs) per event. Beyond its physics performance, this algorithm also provides a rich collection of possibilities for visualization and study of 1D convolutional networks. We will discuss the design, performance, and future potential areas of improvement and study, such as possible ways to recover the full 3D vertex information.
\end{abstract}


\section{Introduction}

% TODO: Write this up

The LHCb detector is facing a major upgrade in luminosity in Run 3 in 2021. In each event, the Poisson average expected for the visible Primary Vertices (PVs) will go from 1.1 to 5.6. In addition, the hardware level-0 trigger is being removed in favor of a purely software trigger running at 30 MHz \cite{CERN-LHCC-2014-016}. Work is ongoing to find new algorithms to support the upgrade era software for LHCb.

The current algorithm for finding vertices is TODO.

An alternate method is proposed here for finding vertices from tracks or hits using machine learning techniques. The algorithm starts with tracks containing location, direction, and covariance matrix information. The tracks in 3D space are converted to a 1D binned ``kernel'' through a process described below. Peaks in this kernel are closely related to the z positions of the primary verticies. We use a series of 1D convolutional layers to predict the PV locations from this kernel. The output probabilities from the neural network are converted to a list of PV candidate z-locations using a simple peak finding algorithm. Using this procedure we have surpassed 90\% efficency with less than 0.2 False Positives (FPs) per event.

A toy simulation of the LHCb detector has been developed to test this algorithm. The design of the algorithm and the toy that is was tested with follows.

\section{Kernel Generation}

The algorithm we are about to describe applies to tracks; though even a simple and inaccurate procedure is sufficient. Our toy simulation generates tracks from PVs and SVs, and we using a simple intersection procedure to produces hits in the Vertex Locater (VELO) according to a simple model of the detector (REF). The hits in the detector are then fed into a ``prototracking'' algorithm, which is a simple but sufficient tracking system 

In order to provide a simple, dense representation for the machine learning algorithm to use, the tracks are transformed into a dense representation using a ``kernel'' procedure. 

\section{Network Design}

The following 

\begin{figure}
   \centering
   \input{nnarch}
   \caption{The final network architecture used in TODO.}
   \label{fig:nnarch}
\end{figure}

\begin{figure}
  \centering
  \input{approach}
  \caption{The final network architecture used in TODO.}
  \label{fig:approach}
\end{figure}

\begin{figure}
	\centering
	\input{kernel}
	\caption{The kernel TODO.}
	\label{fig:kernel}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{images/effntrackspaper.pdf}
	\caption{The Results TODO.}
    \label{fig:results}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=\textwidth]{images/LossPaper.pdf}
	\caption{The Results TODO.}
	\label{fig:loss}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=.8\textwidth]{images/EffVsFP2paper.pdf}
	\caption{The Results TODO.}
	\label{fig:efffp}
\end{figure}




\section{Results}

\section{Plans}

\section*{References}

\bibliography{pvfinder}

\end{document}


